{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N56VGV0ELM3E"
   },
   "source": [
    "<h1><center>HACETTEPE UNIVERSITY</center></h1>\n",
    "<h2><center>COMPUTER SCIENCE & ENGINEERING DEPARTMENT</center></h2>\n",
    "<h2><center>FUNDAMENTALS OF MACHINE LEARNING LAB.</center></h2>\n",
    "<h2><center>3<sup>rd</sup> ASSIGNMENT REPORT</center></h2>\n",
    "<center> ________________ </center>\n",
    "<h3><center>FALL 2019</center></h3>\n",
    "<h3><center>Nur Bengisu ÇAM</center></h3>\n",
    "<h3><center>21627097</center></h3>\n",
    "<h3><center>bengisu.cam@gmail.com</center></h3>\n",
    "<center> ________________ </center>\n",
    " <br>\n",
    "\n",
    " ### **PART 1 -THEORY QUESTIONS**\n",
    " ##### **1.**\n",
    "Asssume that the weights for the neuron are w1 = 3, w2 = −5 and w3 = 2 with the given activation function find the output y values for the input patterns.\n",
    "##### **Answer:**\n",
    "- y1 = 3.1 + (-5).0 + 2.0 = 3 ---->  y' = 1  (after activation function)\n",
    "- y2 = 3.0 + (-5).1 + 2.1 = -5 + 2 = -3 ---->  y' = 0  (after activation function)\n",
    "- y3 = 3.1 + (-5).0 + 2.1 = 3 + 2 = 5 ---->  y' = 1  (after activation function)\n",
    "- y4 = 3.1 + (-5).1 + 2.1 = 3 - 5 + 2 = 0 ---->  y' = 1  (after activation function)\n",
    "\n",
    "##### **2.**\n",
    " Consider the multi-layer neural network.\n",
    " - Find how many weight variables the network has in total (Ignore bias values).\n",
    "Show your calculations.\n",
    "##### **Answer:**\n",
    "    3x4 + 3x2 + 1x1 + 2x2 = 12 + 6 + 1 + 4 = 23\n",
    "\n",
    "- Find how many weight variables the network has in total if the network is\n",
    "considered as fully connected (Ignore bias values).\n",
    "Show your calculations.\n",
    "##### **Answer:**\n",
    "    3x4 + 4x2 + 2x2 = 12 + 8 + 4 = 24\n",
    "\n",
    "- State the dependency information for nodes given number values, which are\n",
    "about which node takes information from which previous node. State also\n",
    "these dependencies for both forward and back-propagation streams.\n",
    "##### **Answer:**\n",
    "    - Node 1: Depends on all of the inputs and effects Node 5, 6, 7, 8.\n",
    "    - Node 2: Depends on all of the inputs and effects Node 5, 7, 8.\n",
    "    - Node 3: Depends on all of the inputs and effects Node 5, 6, 7, 8.\n",
    "    - Node 4: Depends on all of the inputs and effects Node 5, 6, 7, 8.\n",
    "    - Node 5: Depends on all of the inputs and Node 1, 2, 3, 4. Effects Node 7, 8.\n",
    "    - Node 6: Depends on all of the inputs and Node 1, 3, 4. Effects Node 7, 8.\n",
    "    - Node 7: Depends on all of the inputs and Node 1, 2, 3, 4, 5, 6.\n",
    "    - Node 8: Depends on all of the inputs and Node 1, 2, 3, 4, 5, 6.\n",
    "\n",
    "\n",
    "##### **3.**\n",
    "Assume that you have two networks (one in left and one in right). Left one does not contain a hidden layer, rigth one contains a hidden layer consists of 10 units.\n",
    "- Specify an advantage of network in the left over one in the right. Explain\n",
    "your answer.\n",
    "##### **Answer:** \n",
    "    - In the left network, there is no hidden layer so the input layer is directly connected to the output layer. Here there are more parameters needed to update than the right one. This network might give better results with the insufficient dataset/class examples. Because no information is lost in the hidden layer with relatively small units, all the information is directly fed to the output layer.\n",
    "    - In the right network, there is a hidden layer with 10 units. There are less parameters needed to update than the left network. So this will run relatively faster. Also we can use this structure if we have sufficient data/class examples.\n",
    "\n",
    "\n",
    "##### **4.**\n",
    "Consider the network structure. Also you are given the activation function\n",
    "- Write the gradient formulas of the error with respect to the all weight parameters. Show your steps properly.\n",
    "##### **Answer:**\n",
    "\n",
    "$ \\frac{\\partial E}{\\partial w1}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial n1}\n",
    "      * \\frac{\\partial n1}{\\partial w1} \\right)            \n",
    "= 2 (y - t ) *  (-1)*(2 q n_3)^ {q-1}* w_5 * X_1 $      \n",
    "= -2 (y - t ) *(2 q n_3)^ {q-1}* w_5 * X_1 $  \n",
    "      \n",
    "      \n",
    "$ \\frac{\\partial E}{\\partial w2}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial n2}\n",
    "      * \\frac{\\partial n2}{\\partial w2} \\right)       \n",
    " = 2 (y - t ) * (-1)*(2 q n_3)^ {q-1}* w_6 * X_1 $  \n",
    " = -2 (y - t ) *(2 q n_3)^ {q-1}* w_6 * X_1 $   \n",
    "      \n",
    "      \n",
    "$ \\frac{\\partial E}{\\partial w3}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial n1}\n",
    "      * \\frac{\\partial n1}{\\partial w3} \\right)      \n",
    "= 2 (y - t ) * (-1)* (2 q n_3)^ {q-1}* w_5 * X_2 $ \n",
    "= -2 (y - t ) * (2 q n_3)^ {q-1}* w_5 * X_2 $\n",
    "      \n",
    "$ \\frac{\\partial E}{\\partial w4}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial n2}\n",
    "      * \\frac{\\partial n2}{\\partial w4} \\right) \n",
    "= 2 (y - t ) *  (-1)*(2 q n_3)^ {q-1}* w_6 * X_2 $    \n",
    "= -2 (y - t ) *(2 q n_3)^ {q-1}* w_6 * X_2 $\n",
    "      \n",
    "$ \\frac{\\partial E}{\\partial w5}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial w5} \\right) \n",
    "= 2 (y - t ) *  (-1)*(2 q n_3)^ {q-1}* n_1 $\n",
    "= -2 (y - t ) *(2 q n_3)^ {q-1}* n_1 $           \n",
    "      \n",
    "      \n",
    "$ \\frac{\\partial E}{\\partial w6}\n",
    "   =  \\left( \\frac{\\partial E}{\\partial t}\n",
    "      * \\frac{\\partial t}{\\partial n3}\n",
    "      * \\frac{\\partial n3}{\\partial w6} \\right) \n",
    "= 2 (y - t ) *  (-1)* (2 q n_3)^ {q-1}* n_2 $\n",
    "= $-2 (y - t ) * (2 q n_3)^ {q-1}* n_2 $\n",
    "\n",
    " - For q = 1, state that whether the model becomes to a linear regression model\n",
    "or not. Explain why or why not.\n",
    "##### **Answer:** \n",
    "    - Yes, it becomes a linear regression because the activation function becomes linear when q = 1. In the linear regression, the seperation line is linear. Here in this case when q = 1, the seperation line becomes $2 q n_3$, so it is linear and the model becomes a linear regression.\n",
    "\n",
    "\n",
    "##### **5.**\n",
    "Fill the blanks with T(True) or F(False) for the statements below, also explain\n",
    "your reason.\n",
    "- In every condition, a perceptron network perfectly learns a linearly separable\n",
    "function through a finite number of training steps.\n",
    "##### **Answer:** True, because perceptrone can separate linearly separable data.\n",
    "\n",
    "- Single perceptron can compute the XOR function.\n",
    "##### **Answer:** False, because XOR is not linearly separable. We can linearly separate it if we apply transformation to the data and put them into higher dimension.\n",
    "- In backpropagation learning, the model should start with a small learning\n",
    "parameter and slowly increase it while it is in the learning process.\n",
    "##### **Answer:** False, because we first keep learning rate relatively high and after that we reduce the learning rate, make is smaller. If we think it on a curve shaped function, we can take bigger steps for the beginning of the function and when it starts to converge, meaning that we are close to the global minimum, we need to take smaller steps in order not to miss the optimal point.\n",
    "\n",
    "\n",
    "### **PART 2 -CLASSIFICATION OF HERBS USING NEURAL NETWORK**\n",
    "\n",
    " In this assignment, we are required to implement one Neural Network from scratch without using torch library and one Convolutional Neural Network with using the torch library. Here, I implemented a **Neural Network with 0, 1, and 2 hidden layers**. For the Convolutional Neural Network, I implemented **CNN with 1 convolution layer and one fully connected layer, as well as 2 convolution layers and 2 fully connected layers**. Here the dataset consists of 683 classes and 34.225 images in total. This dataset is **imbalanced** meaning that there not equal number of images for each class.  So for any of my models, I could not trained them proparly, even if I changed the hyperparameters. I used different activation functions such as **Sigmoid**, **ReLu** and **LeakyReLu**. I got better results with LeakyReLu, so I kept this hyperparameter static.\n",
    " I will be giving the **loss plots** and at the end of the loss plots, I will give the **accuracies of each model in a Table 1**.\n",
    "\n",
    "#### **1. NN IMPLEMENTATION DETAILS & RESULTS**\n",
    "First of all, I implemented a **multi layered NN with 0, 1 and 2 hidden layers**, keeping 1 input and 1 output layer fixed.  I used the code in the recitation as a baseline and implemented top of it. You can create the desired NN with changing the parameters shown in comments. Here, I tried with hidden layer size, meaning **number of units in the hidden layer, 3, 4, 10 and 20**. I got better results with 20 neurons in each hidden layer. So in the code, it is fixed like this. I used **sigmoid function** as an activation function. However, in the last layer, after the output layer, I used **softmax activation** function to change the class scores into **class probabilities**. First of all all the images goes through the network with the help of the **forward function**. In forward function, the image pixels are multiplacted with the weight of each layer. After the last layer, you can get the **class scores of the image**. When you apply the **softmax function**, you basically get the **class probabilities**. In the **backward phase**, I take the results from the **softmax and the grounf-truth labels**, compare them and calculate loss based on these values. Here I used **MAE loss** as well as **Negative Log likelihood** by simply appliying the $(-1)*numpy.log()$ to the loss I calculated using the softmax result and the ground-truth labels. To **minimize the loss**, I start to take the derivative of each step from last layer to the fisrt layer and **update the wieghts using Gradient Descent Algorithm**. For the Gradient Descent Algorithm, I multiplied the loss with the learning rate and subtracted from the current weights of each layer.\n",
    " #### **1.1 One Hidden Layered NN Results:**\n",
    "Here, I implemented a NN with one input layer, one hidden layer followed with sigmoid activation function and one output layer followed with softmax function.\n",
    "\n",
    "- **PLOT 1**: **3 Units in Hidden Layer & Image size = (80 x 80) & Batch size = 512 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 1](https://drive.google.com/uc?id=1n5Eln0JPxfTRcBRmQ0LVlTnxGOeIfyJf)\n",
    "\n",
    "As you can see from the Plot 1, model did not learn anything. For such a hard classification case with insufficient data, **3 neurons in Hidden Layer is no enough**. Model is underfitting. So I increased the number of units.\n",
    "\n",
    "\n",
    "- **PLOT 2**: **20 Units in Hidden Layer & Image size = (88 x 80) & Batch size = 32 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 2](https://drive.google.com/uc?id=1ajzbtVJEI_OvdMMOlvqQNZmjmW4f7N6F)\n",
    "\n",
    "Here I used 20 neurons in the hidden layer and reduced the batch size since the first model I attempted was not successful with low neuron size and high batch size. As you can see, after the second epoch, the loss decreases drastically and stays the same in the next iteations. Here model is still underfittin because the convergance does not happen, model is not enough again. \n",
    "\n",
    "- **PLOT 3**: **20 Units in Hidden Layer & Image size = (88 x 80) & Batch size = 32 & Learning Rate = 0.001 & Epoch = 10**\n",
    "\n",
    "![Figure 3](https://drive.google.com/uc?id=1NSBok7SnmVa8TJ37-4o53hUjOtSzUst_)\n",
    "\n",
    "As you can see from the Plot 3, the loss value started from a much larger value than the Plot 2. The reason for that is the **learning rate**. When the learning rate is small, it takes small steps on the loss function so in the earlier epochs, the loss becomes higher.\n",
    "\n",
    "- **PLOT 4**: **20 Units in Hidden Layer & Image size = (88 x 80) & Batch size = 32 & Learning Rate = 0.000001 & Epoch = 10**\n",
    "![Figure 4](https://drive.google.com/uc?id=1NLVDDb51G2dZRE21j1CXdSz2FaaUPn8L)\n",
    "As you can see the learning rate here is really low so the loss value is much higher than the PLot 2 and Plot 3. But they all drastically become lower after second epoch. We **cannot talk about the convergence** here. Model is not complex enough, it is still **underfitting**.\n",
    "\n",
    "#### **1.2 Two Hidden Layered NN Results:**\n",
    "First of all, I implemented NN with one input layer, 2 hidden layer each followed with sigmoid activation function and finally an output layer followed with softmax function. \n",
    "- **PLOT 1**: **3 Units in Hidden Layer & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 4](https://drive.google.com/uc?id=1n5Eln0JPxfTRcBRmQ0LVlTnxGOeIfyJf)\n",
    "As you can see, when I use only 3 neurons in hidden layers, the model does not learn anything. So I need to increase the neuron size.\n",
    "\n",
    "- **PLOT 2**: **20 Units in Hidden Layer & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 4](https://drive.google.com/uc?id=1bNoaMQddIU-VSCoQv8Cb_gzHWreVq_Fr)\n",
    "\n",
    "Here, I used 20 neurons in hidden layers, the loss value decreased but still not enough to stop the learning phase. Model is underfitting.\n",
    "\n",
    "#### **1.3 No Hidden Layered NN Results:**\n",
    "\n",
    "First of all, I implemented NN with one input layer,and an output layer followed with softmax function. Basically, there no hidden layers.\n",
    "Here the model starts training, calculates accuracies for train and validation in each epoch but when I want to print the loss values, they return as NaN. I assume this happens either loss value is too big or too small. So for that reason there is no loss graph but i will give accuracies in the Table 1 and Table 2.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #### **2. CNN IMPLEMENTATION DETAILS & RESULTS**\n",
    "    \n",
    " #### **2.1 One Convolutional Layer & One Fully Connected Layer Results:**\n",
    "First of all, I implemented a CNN with **one convolutional layer and one fully connected layer**. I tried different input sizes, different number of units in hidden layers. **Ci** indicates the channels size of the input, here I transformed my images into gray scale so the Ci=1. **Co indicates the number of units in convolutional layer**, here Co=10. **Image Size** is the size of the image, first I resized them and then cropped. **Batch size** is the number of images to be send to the model. **Learning rate** is the parameter for training phase, used to **update the weights with Gradient Descent Algorithm**. **Epoch** size is the number of times that the whole train data will be send through the model. Mostly, I used 10 epoch otherwise training phase took too much time and the accuracies did not changed that much. Here are the results of the CNN for different combinations of hyperparameters:\n",
    "\n",
    "- **PLOT 1**: **Co = 10 (number of units in Convolutional Layer)& Image size = (48 x 48) & Batch size = 32 & Learning Rate = 0.01 & Epoch = 10**\n",
    "\n",
    "![Figure 1](https://drive.google.com/uc?id=1PaJOoiTuXFSVW9TeQj_atyYVYg1Bo4zk)\n",
    "\n",
    "In the Plot 1, I draw the validation and training loss values. Here, I used the images with size of 48x48. It is a quite small image size. The detail informations most probably gone when I resized them into that small size. But I wanted to try with small size of images just to make the learning process **faster**. As you can see from the Plot 1 , the model did not train. For me, the **learning rate is quite big** for this kind of challening dataset. Also the number of epochs must be higher, but that requires too much time. I need more strong hardware to make it happen. Basically, the **model is underfitting**. **Not complex enough** to classify the given images. Since I coul not trained the model, I decided to use **smaller and smaller learning rates**.\n",
    "\n",
    "- **PLOT 2**: **Co = 10 & Image size = (48 x 48) & Batch size = 32 & Learning Rate = 0.001 & Epoch = 10**\n",
    "![Figure 2](https://drive.google.com/uc?id=1Vf9h-j2X0gVwdcmXhfhp6Bg69ceRAvs_)\n",
    "\n",
    "In the Plot 2, you can see that the loss values are the same with the Plot 1. This is becase the **image size is too small**. The model cannot learn even with the smaller learning rates.Basically, the **model is underfitting**. **Not complex enough** to classify the given images.\n",
    "\n",
    "\n",
    "- **PLOT 3**: **Co = 10 & Image size = (48 x 48) & Batch size = 32 & Learning Rate = 0.00001 & Epoch = 10**\n",
    "![Figure 3](https://drive.google.com/uc?id=1QIE_gMqMrPAD4vdu-7etbSDpBiRHhmjw)\n",
    "\n",
    "In the Plot 3, you can see that the loss values are the same with the Plot 1 and Plot 2. This is becase the **image size is too small**. The model cannot learn even with the smaller learning rates.Basically, the **model is underfitting**. **Not complex enough** to classify the given images.\n",
    "\n",
    "- **PLOT 4**: **Co = 10 & Image size = (48 x 48) & Batch size = 32 & Learning Rate = 0.000001 & Epoch = 10**\n",
    "![Figure 4](https://drive.google.com/uc?id=1vT4l5TS-C-_RWHvenR-ylsnBOVh0kXS4)\n",
    "\n",
    "One more same result with the previous plots. The reason is the same, **images are not informative enough**.Basically, the **model is underfitting**. **Not complex enough** to classify the given images.\n",
    "**I did not tried with larger batch values because the model already underfits. The larger the batch value, the larger the possibility of loosing information in a batch.So, I did not used larger batch values for this model.**\n",
    "\n",
    "- **PLOT 5**: **Co = 10 & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.05 & Epoch = 10**\n",
    "\n",
    "![Figure 5](https://drive.google.com/uc?id=1BwNcVTNBFbFxJh2rX5H4fChX23ivyZxb)\n",
    "\n",
    "In Plot 5, I used **larger sized images**, **80 x 80**,  since the previous size was not informative enough. Here I used quite big learning rate, for that reason model is not trained. The comlexity of the model is low and it is **underfitting**.\n",
    "\n",
    "- **PLOT 6**: **Co = 10 & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.001 & Epoch = 10**\n",
    "\n",
    "![Figure 6](https://drive.google.com/uc?id=1F1xiWM4oAg5J0JOu8aLlEABDj47qO9w9)\n",
    "\n",
    "In Plot 6, the model **finally started to learn**. Different from the Plot 5, I used **smaller learning rate** and it worked. But still the model **did not coverge** so the training is not over. It need more epoch and maybe smaller learning rate.\n",
    "\n",
    " #### **2.2 Two Convolutional Layer & Two Fully Connected Layer Results:**\n",
    "In generally speaking, if you increase the number of layers in the network, it is better up to some number. From some number of layers, model starts to overfit because the complexity increases too much for the given dataset. In this assignment, I experimented that when I increase the number of layers, I got better results, my model finally started to learn. This classification problem is hard due to insufficient data and lack of complexity of the model.\n",
    "\n",
    " - **PLOT 1**: **Co = 10 & Image size = (80 x 80) & Batch size = 512 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 1](https://drive.google.com/uc?id=1SJeeVi4_ELaIvPLLftGshXYp9ZQh6l4e)\n",
    "\n",
    "In the Plot 1 for CNN with 2 convolution and 2 fully connected layer, I used **larger batch size**, the learning rate is also big. When the batch size is high, each image loose some information because the gradient is calculate for the total of the images in the batch. But larger batch size decreases the train time. Here the model did not learn, it is basically underfitting.\n",
    "\n",
    "\n",
    "- **PLOT 2**: **Co = 10 & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.05 & Epoch = 10**\n",
    "![Figure 2](https://drive.google.com/uc?id=1zSu8wM73VGGxIyRmsX-qrWO-ma0SiuC1)\n",
    "\n",
    "In Plot 2, if we compare it with Plot 1, the **only difference is the batch size**. Batch size is **smaller** than the Plot 1 and it worked better. We can see the **effect of the learning rate** with these two examples. Its better when it is small for this dataset.\n",
    "\n",
    "- **PLOT 3**: **Co = 10 & Image size = (80 x 80) & Batch size = 32 & Learning Rate = 0.5 & Epoch = 10**\n",
    "![Figure 3](https://drive.google.com/uc?id=1kMMR8JvuwfT5zp_UJF9mfT8_PLhNUKQd)\n",
    "\n",
    "When I tried the same combinations with **larger learning rate**, you can see the result is not better. In this example, we can see when the learning rate is small, it is better. It shows the **effect of the learning rate**. Model is still underfitting.\n",
    "\n",
    "\n",
    "\n",
    "#### **CONCLUSION**\n",
    "\n",
    "In this assignment, I experimented that when I increase the number of layers, I got better results, my model finally started to learn. This classification problem is hard due to insufficient data and lack of complexity of the model.\n",
    "I implemented and trained NN with 0,1,2 hidden layers, calculated the MAE loss and negative log likelihood. I got better results with 2 convolution and 2 fully connecte layered CNN. You can see the overall accuracies of each model in the below table. Table 1 is for CNN accuraies, Table 2 is for NN accuracies.\n",
    "I calculte the best accuracy among all the epoch for **early stopping**. But the model never converges, never perfectly fits so I did not cut the training. **None of my models overfits due to lack of sufficient data and model complexity**.\n",
    "\n",
    "\n",
    "\n",
    "| $CNN Models$ | $Image Size$ | $Convolution Units$ |$Epoch$ | $Convolution$ |$Fully Connected$ |$Batch size$ |$Learning Rate$ | $Train ACC$ |$Validation ACC$ |\n",
    "| :---: | :---: | :---: | :---: |:---: | :---: | :---: |:---: | :---: |:---: |\n",
    "| Plot 1 | 48 x 48 | 10 |32 | 1 | 1 | 10 | 0.05 | 0.0196 |0.020 |\n",
    "| Plot 2 | 48 x 48 | 10 |32 | 1 | 1 | 10 | 0.001 | 0.0161 |0.071 | \n",
    "| Plot 3 | 48 x 48 | 10 |32 | 1 | 1 | 10 | 0.00001 | 0.0013 |0.0012 |\n",
    "| Plot 4 | 48 x 48 | 10 |32 | 1 | 1 | 10 | 0.000001 | 0.0011 |0.0006 |\n",
    "| Plot 5 | 80 x 80 | 10 |32 | 1 | 1 | 10 |0.05 | 0.0196 |0.020 |\n",
    "| Plot 6 | 80x 80 | 10 |32 | 1 | 1 | 10 | 0.001 | 0.0196 |0.020 |\n",
    "| Plot 1 | 80 x 80 | 10 |512 | 2 | 2 | 10 | 0.05 |0.0015 | 0.0019 |\n",
    "| Plot 2 | 80 x 80 | 10 |32 | 2 | 2 | 10 | 0.05 | 0.0196 | 0.020 |\n",
    "| Plot 3 | 80 x 80 | 10 |32 | 2 | 2 | 10 | 0.5 |0.132 | 0.142 |\n",
    "\n",
    "Table 1.\n",
    "\n",
    "\n",
    "| $NN Models$ | $Image Size$ | $Hidden Units$ |$Epoch$ | $Hidden Size$ |$Batch size$ |$Learning Rate$ | $Train ACC$ |$Validation ACC$ |\n",
    "| :---: | :---: | :---: | :---: |:---: | :---: | :---: |:---: | :---: |\n",
    "| Plot 1 | 80 x 80 | 3 | 512 | 1 | 10 | 0.05 | 0.0019 |0.018 |\n",
    "| Plot 2 | 80 x 80 | 20 | 32 | 1 | 10 | 0.001 | 0.0012 |0.0010 | \n",
    "| Plot 3 | 80 x 80 | 20 | 32 | 1 | 10 | 0.00001 | 0.0011 |0.0010 |\n",
    "| Plot 1 | 80 x 80 | 3 | 32 | 2 | 10 | 0.05 | 0.0007 |0.0003 |\n",
    "| Plot 2 | 80 x 80 | 20 | 32 | 2 | 10 | 0.001 | 0.0006 |0.0004 |\n",
    "| Plot 1 | 80 x 80 | - | 32 | 0 | 10 | 0.05 | 0.0006 |0.0004 |\n",
    "| Plot 2 | 80 x 80 | - | 32 | 0 | 10 | 0.001 | 0.0006 |0.0003 |\n",
    "\n",
    "Table 2.\n",
    "\n",
    "\n",
    "As you can see above tables, I got the best accuracy with CNN, the very first row of combinations. Generally, my models are not trained enough, they need much more higher epoch number as well as much complex models.\n",
    "\n",
    "\n",
    "#### **REFERENCES**\n",
    "- For the implementation of NN, I used the one in recitations as a baseline.\n",
    "- For CNN implementation and training code, I referenced from my past assignments in BBM416-Fundamentals of Computer Vision.\n",
    "- I used pytorch, numpy libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPHboiCDLEXF"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "## GIVE THE FILE PATHS ACCOURDINGLY ##\n",
    "######################################\n",
    "labels_path = r\"C:\\Users\\bengi\\Downloads\\Train_Info.csv\" \n",
    "path = r\"C:\\Users\\bengi\\Desktop\\4.G\\train_resized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsN1BccuLuxZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Class       Path\n",
      "0          0      0      0.jpg\n",
      "1          1      0      1.jpg\n",
      "2          2      0      2.jpg\n",
      "3          3      0      3.jpg\n",
      "4          4      0      4.jpg\n",
      "...      ...    ...        ...\n",
      "34220  34220     99  34220.jpg\n",
      "34221  34221     99  34221.jpg\n",
      "34222  34222     99  34222.jpg\n",
      "34223  34223     99  34223.jpg\n",
      "34224  34224     99  34224.jpg\n",
      "\n",
      "[34225 rows x 3 columns]\n",
      "(20535, 3)\n",
      "(6845, 3)\n",
      "(6845, 3)\n",
      "          Id  Class       Path\n",
      "0       7789    243   7789.jpg\n",
      "1      20792    494  20792.jpg\n",
      "2      33263     81  33263.jpg\n",
      "3      10246    300  10246.jpg\n",
      "4      31832    664  31832.jpg\n",
      "...      ...    ...        ...\n",
      "20530   5425    195   5425.jpg\n",
      "20531   5858    200   5858.jpg\n",
      "20532  26310    563  26310.jpg\n",
      "20533  15255    388  15255.jpg\n",
      "20534   9225    275   9225.jpg\n",
      "\n",
      "[20535 rows x 3 columns]\n",
      "         Id  Class       Path\n",
      "0     11723    325  11723.jpg\n",
      "1     21489    504  21489.jpg\n",
      "2      7921    247   7921.jpg\n",
      "3     19887    470  19887.jpg\n",
      "4     21457    504  21457.jpg\n",
      "...     ...    ...        ...\n",
      "6840  12526    335  12526.jpg\n",
      "6841   2219    132   2219.jpg\n",
      "6842   6287    207   6287.jpg\n",
      "6843  15189    388  15189.jpg\n",
      "6844  22613    517  22613.jpg\n",
      "\n",
      "[6845 rows x 3 columns]\n",
      "         Id  Class       Path\n",
      "0     13159    345  13159.jpg\n",
      "1     27177    587  27177.jpg\n",
      "2     28431    612  28431.jpg\n",
      "3     16561    412  16561.jpg\n",
      "4      7196    229   7196.jpg\n",
      "...     ...    ...        ...\n",
      "6840   1175    117   1175.jpg\n",
      "6841  31974    667  31974.jpg\n",
      "6842  29144    627  29144.jpg\n",
      "6843  16068    401  16068.jpg\n",
      "6844   6426    208   6426.jpg\n",
      "\n",
      "[6845 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "######## RUN THIS CODE CELL ######\n",
    "##################################\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torch import nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "ALL = \"train_resized\"\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv(labels_path, delimiter= \",\")\n",
    "labels_df.insert(2,\"Path\",\"\",True)\n",
    "\n",
    "index = labels_df.index\n",
    "columns = labels_df.columns\n",
    "values = labels_df.Id.values\n",
    "\n",
    "\n",
    "for img_id in values:\n",
    "    labels_df.loc[img_id, \"Path\"] = str(img_id) + '.jpg'\n",
    "\n",
    "print(labels_df)\n",
    "train, test = train_test_split(labels_df, test_size=0.40, shuffle=True)\n",
    "test, val = train_test_split(test, test_size=0.50, shuffle=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(val.shape)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "print(train)\n",
    "print(test)\n",
    "print(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fB6L4yVbLx_C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(10, 10, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (activation): LeakyReLU(negative_slope=0.1)\n",
      "  (linear1): Linear(in_features=4410, out_features=1366, bias=True)\n",
      "  (linear2): Linear(in_features=1366, out_features=683, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CODE CELL EVERYTIME WITH SETTING THE PARAMETERS\n",
    "#####################################\n",
    "###### SET THE PARAMETERS CNN #######\n",
    "#####################################\n",
    "# parameters for training the CNN model\n",
    "\n",
    "batch_size_cnn = 32       #tried 16, 32\n",
    "epoch_cnn = 10             #tried 20\n",
    "learning_rate_cnn = 0.05   # tried 0.5 0.05 0.005 0.00001 and 0.001 and 0.00001\n",
    "num_of_conv = 2           # number of convolutional layer, you can change number of convolution layer with this parameter\n",
    "num_of_fc = 2            # number of fully connected layer, you can change number of fully connected layer with this parameter\n",
    "\n",
    "Ci = 1   # channel number, for gray scale images it is 1\n",
    "Co = 10  # number of units in convolution layer\n",
    "K_size = 2  # convolutional kernel size\n",
    "P_size = 1  # convolutional padding size\n",
    "S_size = 2  # convolutional stride size\n",
    "num_of_classes = 683\n",
    "image_size = 80    #tried 48, 100\n",
    "activation_func = \"LeakyRelu\"   #tried ReLu, Sigmoid\n",
    "\n",
    "#####################################\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "def calculate_out_size(input_size, kernel_size, padding, stride):\n",
    "\n",
    "    return int(((input_size - kernel_size) +  2*padding) / stride) +1\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        # conv layer1\n",
    "        self.conv1 = nn.Conv2d(in_channels=Ci, out_channels=Co, kernel_size=K_size, padding=P_size, stride=S_size)\n",
    "        out_size = calculate_out_size(image_size,K_size, P_size, S_size)\n",
    "        \n",
    "        if(num_of_conv ==  2):\n",
    "            self.conv2 = nn.Conv2d(in_channels= Co, out_channels= Co, kernel_size=K_size, padding=P_size, stride=S_size)\n",
    "            out_size = calculate_out_size(out_size,K_size, P_size, S_size)           \n",
    "        \n",
    "        if(activation_func == \"LeakyRelu\"):\n",
    "            self.activation = nn.LeakyReLU(0.1)\n",
    "        if(activation_func == \"ReLu\"):\n",
    "            self.activation = nn.ReLU()\n",
    "        if(activation_func == \"Sigmoid\"):\n",
    "            self.activation = nn.Sigmoid()\n",
    "        \n",
    "        # calculate feature size\n",
    "        feature_size = out_size*out_size*Co  # Co out_channel of conv2\n",
    "\n",
    "        # create multiple times of FC layer\n",
    "        next_input_features = num_of_classes*num_of_fc\n",
    "        self.linear1 = nn.Linear(feature_size, next_input_features)\n",
    "        \n",
    "        if(num_of_fc ==  2):\n",
    "            self.linear2 = nn.Linear(next_input_features, num_of_classes) \n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x) \n",
    "        if(num_of_conv == 2):\n",
    "            x = self.conv2(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        if(num_of_fc == 2):\n",
    "            x = self.linear2(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "cnn_model = CNN()\n",
    "\n",
    "print(cnn_model)\n",
    "\n",
    "optimizer1 = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate_cnn)\n",
    "optimizer2 = torch.optim.SGD(cnn_model.parameters(), lr=learning_rate_cnn, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09ECdHgkL1yS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.NN object at 0x000002074510DA20>\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CODE CELL EVERYTIME WITH SETTING THE PARAMETERS\n",
    "#####################################\n",
    "####### SET THE PARAMETERS NN #######\n",
    "#####################################\n",
    "# parameters for training the NN model  \n",
    "\n",
    "batch_size_nn = 32       #tried 16, 32\n",
    "epoch_nn = 10             #tried 20\n",
    "learning_rate_nn = 0.05  # tried 0.00001 and 0.001 and 0.00001\n",
    "lr = learning_rate_nn\n",
    "\n",
    "num_of_hidden = 2    # number of hidden layer, you can change the number of hidden layer with changing this value\n",
    "num_of_classes = 683\n",
    "image_size = 80\n",
    "\n",
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NN(object):\n",
    "    def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 1*80*80\n",
    "        self.outputSize = num_of_classes\n",
    "        self.hiddenSize = 20\n",
    "\n",
    "        #weights\n",
    "        if(num_of_hidden == 0):\n",
    "            self.W1 = np.random.randn(self.inputSize, self.outputSize) # weight matrix from input to hidden layer\n",
    "        if(num_of_hidden == 1):\n",
    "            self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # weight matrix from input to hidden layer\n",
    "            self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # weight matrix from hidden to output layer\n",
    "        if(num_of_hidden == 2):\n",
    "            self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # weight matrix from input to hidden layer\n",
    "            self.W2 = np.random.randn(self.hiddenSize, self.hiddenSize) # weight matrix from hidden to output layer\n",
    "            self.W3 = np.random.randn(self.hiddenSize, self.outputSize) # weight matrix from input to hidden layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        #forward propagation through our network\n",
    "        if(num_of_hidden == 0):\n",
    "            self.z = np.dot(X, self.W1) # dot product of X (input) and first set of weights\n",
    "            o = self.sigmoid(self.z) # final activation function\n",
    "            \n",
    "        if(num_of_hidden == 1):\n",
    "            self.z = np.dot(X, self.W1) # dot product of X (input) and first set of weights\n",
    "            self.z2 = self.sigmoid(self.z) # activation function number 1\n",
    "            self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of weights\n",
    "            o = self.sigmoid(self.z3) # final activation function\n",
    "            \n",
    "        if(num_of_hidden == 2):\n",
    "            self.z = np.dot(X, self.W1) # dot product of X (input) and first set of weights\n",
    "            self.z2 = self.sigmoid(self.z) # activation function number 1\n",
    "            self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer z2 and second set of weights\n",
    "            self.z4 = self.sigmoid(self.z3) # activation function number 2\n",
    "            self.z5 = np.dot(self.z4, self.W3) # dot product of hidden layer z4 and second set of weights\n",
    "            o = self.sigmoid(self.z5) # final activation function\n",
    "            \n",
    "        return o\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        # activation function\n",
    "        return 1/(1+np.exp(s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of sigmoid\n",
    "        return self.sigmoid(s)*(1-self.sigmoid(s))\n",
    "    \n",
    "    def softmax(self,s):\n",
    "        return np.exp(s)/sum(np.exp(s))\n",
    "    \n",
    "    def softmaxPrime(self,s):\n",
    "        return np.exp(s)/sum(np.exp(s))\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "             \n",
    "      \n",
    "        if(num_of_hidden == 0):\n",
    "            # backward propagate through the network\n",
    "            self.o_error = y - o # error in output\n",
    "            self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "            \n",
    "            self.W1 -= X.T.dot(self.o_delta)*lr*2 # adjusting first set (input --> hidden) weights\n",
    "            \n",
    "        if(num_of_hidden == 1):\n",
    "            # backward propagate through the network\n",
    "            self.o_error = y - o # error in output\n",
    "            self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error   \n",
    "        \n",
    "            self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer #1 weights contributed to output error\n",
    "            self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "            self.W1 -= X.T.dot(self.z2_delta)*lr*2 # adjusting first set (input --> hidden) weights\n",
    "            self.W2 -= self.z2.T.dot(self.o_delta)*lr*2 # adjusting second set (hidden --> output) weights\n",
    "        \n",
    "        if(num_of_hidden == 2):\n",
    "            # backward propagate through the network\n",
    "            self.o_error = y - o # error in output\n",
    "            self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "            \n",
    "            self.z4_error = self.o_delta.dot(self.W3.T) # z2 error: how much our hidden layer #2 weights contributed to output error\n",
    "            self.z4_delta = self.z4_error*self.sigmoidPrime(self.z4) # applying derivative of sigmoid to z4 error\n",
    "            self.z2_error = self.z4_delta.dot(self.W2.T) # z2 error: how much our hidden layer #1 weights contributed to output error\n",
    "            self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "            \n",
    "\n",
    "            self.W1 -= X.T.dot(self.z2_delta)*lr*2 # adjusting first set (input --> hidden) weights\n",
    "            self.W2 -= self.z2.T.dot(self.z4_delta)*lr*2 # adjusting second set (hidden --> output) weights\n",
    "            self.W3 -= self.z3.T.dot(self.o_delta)*lr*2 # adjusting second set (hidden --> output) weights\n",
    "            \n",
    "    def train(self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "\n",
    "        \n",
    "optimizer1 = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate_nn)\n",
    "optimizer2 = torch.optim.SGD(cnn_model.parameters(), lr=learning_rate_nn, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "nn_model = NN()\n",
    "print(nn_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BLdBNw-L5d6"
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "### RUN THIS CODE CELL EVERYTIME FOR TRAINING THE MODEL #########\n",
    "## train_model() FUNCTION WILL BE CALLED IN THE NEXT CODE CELL ##\n",
    "###### TO START THE TRAIN PROCESS, RUN THE NEXT CODE CELL #######\n",
    "#################################################################\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([transforms.Resize(80),\n",
    "                                      transforms.CenterCrop(80),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485], [0.229])                                       \n",
    "                                    ])\n",
    "\n",
    "\n",
    "\n",
    "#loss and acc arrays to draw the plot later\n",
    "loss_arr_val = numpy.array([])\n",
    "loss_arr_tr = numpy.array([]) \n",
    "\n",
    "def train_model(tr_model, batch_size, num_epochs, train_data, val_data, optimizer, learning_rate):\n",
    "\n",
    "    global loss_arr_val\n",
    "    global loss_arr_tr\n",
    "    \n",
    "    # best_model_wts = copy.deepcopy(tr_model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    train_size = train_data.shape[0]\n",
    "    val_size = val_data.shape[0]\n",
    "         \n",
    "\n",
    "    for i in range(num_epochs):\n",
    "\n",
    "        running_loss_t = 0\n",
    "        running_corrects_t = 0\n",
    "        running_loss_v = 0\n",
    "        running_corrects_v = 0\n",
    "        print('Epoch {}/{}'.format(i, num_epochs - 1))\n",
    "        print('-' * batch_size) \n",
    "\n",
    "        flag = 0        \n",
    "        #set the model to the training mode\n",
    "        if(tr_model == cnn_model):\n",
    "            tr_model.train()              \n",
    "        \n",
    "            \n",
    "\n",
    "        pointer = 0\n",
    "        for j in range(train_size//batch_size):   \n",
    "            sub_pointer = 0\n",
    "            #image_batch = numpy.array([[[]]])\n",
    "            image_batch = numpy.empty((1,1,80,80)) #batch, depth, width, height\n",
    "            while(sub_pointer < batch_size):\n",
    "                ind = pointer + sub_pointer\n",
    "                img_name = train_data.Path.iloc[ind:(ind + 1)].values[0]\n",
    "                #print(\"train....\" +  img_name + \" p....\" + str(pointer)+ \" subp....\" + str(sub_pointer) )\n",
    "                sub_pointer += 1\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                image = Image.open(img_path).convert('L')\n",
    "                image = transformations(image)\n",
    "                image = numpy.array(image)\n",
    "                image = numpy.expand_dims(image, axis = 0)\n",
    "                #image = numpy.expand_dims(image, axis = 0)\n",
    "                #image_batch = numpy.vstack((image_batch, image))  #bu da oluyo\n",
    "                image_batch = numpy.concatenate((image_batch, image), axis =0)  # bu da oluyo\n",
    "            image_batch = numpy.delete(image_batch, 0, 0)\n",
    "            image_tensor = torch.from_numpy(image_batch).float()\n",
    "            # print(image_tensor.device)  ---> cuda:0\n",
    "            img_batch_labels = train_data.Class.iloc[pointer:(pointer + batch_size)].to_numpy()\n",
    "            img_batch_labels = torch.from_numpy(img_batch_labels)\n",
    "            # print(img_batch_labels.device)   ---> cuda:0\n",
    "\n",
    "            \n",
    "            \n",
    "            if(tr_model == cnn_model): \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tr_model(image_tensor)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, img_batch_labels)\n",
    "                #ONLY FOR TRAIN:\n",
    "                # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # Calling the step function on an Optimizer makes an update to its parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss_t += loss.item() * batch_size  \n",
    "                running_corrects_t += torch.sum(preds == img_batch_labels.data)\n",
    "                \n",
    "            if(tr_model == nn_model):\n",
    "                X1_reshaped = image_tensor.reshape(-1, image_tensor.shape[0])\n",
    "                X1_tr = numpy.transpose(X1_reshaped)\n",
    "                forward_result = tr_model.forward(X1_tr)\n",
    "                outputs = torch.from_numpy(forward_result).float()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                X = X1_tr.cpu().detach().numpy()\n",
    "                y = img_batch_labels.cpu().detach().numpy()\n",
    "                \n",
    "                y2 = numpy.empty((batch_size,683))\n",
    "                for i in range(batch_size):\n",
    "                    label = y[i]\n",
    "                    y2[i][label-1] = 1\n",
    "                \n",
    "                \n",
    "                tr_model.train(X, y2)\n",
    "                \n",
    "                #loss = criterion(outputs, img_batch_labels)   \n",
    "                #loss = np.mean(np.square(y2 - forward_result))\n",
    "                loss = np.log(y2 - forward_result)*(-1)\n",
    "                \n",
    "                \n",
    "                # statistics\n",
    "                running_loss_t += loss * batch_size  \n",
    "                running_corrects_t += torch.sum(preds == img_batch_labels.data)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            pointer += sub_pointer\n",
    "            #print(pointer)\n",
    "\n",
    "        epoch_loss = running_loss_t / train_size\n",
    "        epoch_acc = running_corrects_t.double() / train_size\n",
    "        loss_arr_tr = numpy.append(loss_arr_tr, epoch_loss)\n",
    "        \n",
    "        #print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        print(\"Train Loss : \", epoch_loss)\n",
    "        print(\"Train Acc: \", epoch_acc)\n",
    "        \n",
    "\n",
    "        # take the model into evaluation mode\n",
    "        if(tr_model == cnn_model):\n",
    "            tr_model.train(False)\n",
    "            tr_model.eval()\n",
    "\n",
    "        flag = 1\n",
    "        pointer = 0\n",
    "        for j in range(val_size//batch_size):\n",
    "            sub_pointer = 0\n",
    "            #image_batch = numpy.array([[[]]])\n",
    "            image_batch = numpy.empty((1,1,80,80)) #batch, depth, width, height\n",
    "            while(sub_pointer < batch_size):\n",
    "                ind = pointer + sub_pointer\n",
    "                img_name = val_data.Path.iloc[ind:(ind + 1)].values[0]\n",
    "                #print(\"val....\" + img_name + \" p....\" + str(pointer)+ \" subp....\" + str(sub_pointer) )\n",
    "                sub_pointer += 1\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                image = Image.open(img_path).convert('L')\n",
    "                image = transformations(image)\n",
    "                image = numpy.array(image)\n",
    "                image = numpy.expand_dims(image, axis = 0)\n",
    "                #image = numpy.expand_dims(image, axis = 0)\n",
    "                #image_batch = numpy.vstack((image_batch, image))  bu da oluyo\n",
    "                image_batch = numpy.concatenate((image_batch, image), axis =0)  # bu da oluyo\n",
    "            image_batch = numpy.delete(image_batch, 0, 0)\n",
    "            image_tensor = torch.from_numpy(image_batch).float()\n",
    "            img_batch_labels = val_data.Class.iloc[pointer:(pointer + batch_size)].to_numpy()\n",
    "            img_batch_labels = torch.from_numpy(img_batch_labels)\n",
    "            \n",
    "\n",
    "            if(tr_model == cnn_model):  \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tr_model(image_tensor)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, img_batch_labels)\n",
    "                \n",
    "\n",
    "                # statistics\n",
    "                running_loss_v += loss.item() * batch_size  \n",
    "                running_corrects_v += torch.sum(preds == img_batch_labels.data)\n",
    "                \n",
    "            if(tr_model == nn_model):\n",
    "                X1_reshaped = image_tensor.reshape(-1, image_tensor.shape[0])\n",
    "                X1_tr = numpy.transpose(X1_reshaped)\n",
    "                forward_result = tr_model.forward(X1_tr)\n",
    "                outputs = torch.from_numpy(forward_result).float()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                                \n",
    "                X = X1_tr.cpu().detach().numpy()\n",
    "                y = img_batch_labels.cpu().detach().numpy()\n",
    "                \n",
    "                y2 = numpy.zeros((batch_size,683))\n",
    "                for i in range(batch_size):\n",
    "                    label = y[i]\n",
    "                    y2[i][label-1] = 1\n",
    "                \n",
    "                tr_model.train(X, y2)\n",
    "                \n",
    "                #loss = criterion(outputs, img_batch_labels)   \n",
    "                #loss = np.mean(np.square(y2 - forward_result))\n",
    "                loss = np.log(y2 - forward_result)*(-1)\n",
    "                \n",
    "                # statistics\n",
    "                running_loss_v += loss * batch_size  \n",
    "                running_corrects_v += torch.sum(preds == img_batch_labels.data)\n",
    "                \n",
    "                \n",
    "            pointer += sub_pointer\n",
    "\n",
    "        epoch_loss = running_loss_v / val_size\n",
    "        epoch_acc = running_corrects_v.double() / val_size\n",
    "        loss_arr_val = numpy.append(loss_arr_val, epoch_loss)\n",
    "        #print('Validation Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "        print(\"Validation Loss : \", epoch_loss)\n",
    "        print(\"Validation Acc: \", epoch_acc)\n",
    "        \n",
    "        if(flag and epoch_acc > best_acc):\n",
    "            best_acc = epoch_acc\n",
    "#             best_model_wts = copy.deepcopy(tr_model.state_dict())\n",
    "#     tr_model.load_state_dict(best_model_wts)  \n",
    "#     #save these arrays to draw the plot\n",
    "#     numpy.save('lossVal.npy', loss_arr_val)   \n",
    "#     numpy.save('lossTrain.npy', loss_arr_tr)\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F898gpPoMJEX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702531055258\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477646866012\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 1/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702529569133\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477646866012\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 2/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702526596883\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477646866012\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 3/9\n",
      "--------------------------------\n",
      "Train Loss :  6.50270252585382\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477644636825\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 4/9\n",
      "--------------------------------\n",
      "Train Loss :  6.50270252288157\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477644636825\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 5/9\n",
      "--------------------------------\n",
      "Train Loss :  6.50270251990932\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477646866012\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 6/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702516194008\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477642407636\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 7/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702516194008\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477642407636\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 8/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702513221758\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477642407636\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n",
      "Epoch 9/9\n",
      "--------------------------------\n",
      "Train Loss :  6.502702511735633\n",
      "Train Acc:  tensor(0.0190, dtype=torch.float64)\n",
      "Validation Loss :  6.481477640178449\n",
      "Validation Acc:  tensor(0.0199, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "######## TRAIN CNN MODEL ############\n",
    "#####################################\n",
    "# REMOVE THE COMMENT TAG, IF YOU WANT TO RUN CNN\n",
    "\n",
    "train_model(cnn_model, batch_size_cnn, epoch_cnn, train, val,optimizer2, learning_rate_cnn)\n",
    "\n",
    "\n",
    "#####################################\n",
    "######## TRAIN NN MODEL ############\n",
    "#####################################\n",
    "# REMOVE THE COMMENT TAG, IF YOU WANT TO RUN NN\n",
    "\n",
    "#train_model(nn_model, batch_size_nn, epoch_nn, train, val,optimizer2, learning_rate_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiWMesX-MKRG"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "###### LOSS PLOT DRAWING #######\n",
    "################################\n",
    "# draw the loss and acc plot for the bestModel\n",
    "# x axis for number of epochs\n",
    "# y axis for loss values of validation and tr\n",
    "x_axis = ([1,2,3,4,5,6,7,8,9,10])\n",
    "plt.plot(x_axis, loss_arr_val, label = \"val_loss\") \n",
    "plt.plot(x_axis, loss_arr_tr, label = \"train_loss\") \n",
    "\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('epochs') \n",
    "# naming the y axis \n",
    "plt.ylabel('loss value') \n",
    "  \n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "report_and_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
